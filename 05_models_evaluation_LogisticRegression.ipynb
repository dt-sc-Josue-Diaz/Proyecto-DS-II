{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ebe164-25f4-4935-9720-c8c2a3ad59cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SeriousDlqin2yrs', 'RevolvingUtilizationOfUnsecuredLines', 'age',\n",
       "       'NumberOfTime30-59DaysPastDueNotWorse', 'DebtRatio', 'MonthlyIncome',\n",
       "       'NumberOfOpenCreditLinesAndLoans', 'NumberOfTimes90DaysLate',\n",
       "       'NumberRealEstateLoansOrLines', 'NumberOfTime60-89DaysPastDueNotWorse',\n",
       "       'NumberOfDependents'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/dt-sc-Josue-Diaz/preentrega/refs/heads/main/data_credit_training.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a759dedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MonthlyIncome'] = df['MonthlyIncome'].fillna(df['MonthlyIncome'].median())\n",
    "df['NumberOfDependents'] = df['NumberOfDependents'].fillna(0)  # Si 0 tiene sentido\n",
    "df['DebtRatio'] = df['DebtRatio'].clip(upper=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3265f03b-8937-462f-a9c2-f911f113f920",
   "metadata": {},
   "source": [
    "# Regresion logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6623b04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_lg = pd.read_csv(\"https://raw.githubusercontent.com/dt-sc-Josue-Diaz/Proyecto-DS-II/refs/heads/main/05_models_evaluation/data_para_entrenamiento.csv\")\n",
    "X = df_lg.drop(columns=['moroso'])\n",
    "y = df_lg['moroso']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f126affc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluación en entrenamiento:\n",
      "Accuracy: 0.9338524730446688\n",
      "\n",
      "Reporte de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97    108955\n",
      "           1       0.59      0.07      0.13      7905\n",
      "\n",
      "    accuracy                           0.93    116860\n",
      "   macro avg       0.76      0.54      0.55    116860\n",
      "weighted avg       0.91      0.93      0.91    116860\n",
      "\n",
      "Evaluación en prueba:\n",
      "Accuracy: 0.935446330777656\n",
      "\n",
      "Reporte de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97     27274\n",
      "           1       0.61      0.08      0.14      1942\n",
      "\n",
      "    accuracy                           0.94     29216\n",
      "   macro avg       0.78      0.54      0.55     29216\n",
      "weighted avg       0.92      0.94      0.91     29216\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dtscj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Dividir los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear y entrenar el modelo\n",
    "model = LogisticRegression(max_iter=1500)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar en entrenamiento\n",
    "y_train_pred = model.predict(X_train)\n",
    "print(\"Evaluación en entrenamiento:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_train, y_train_pred))\n",
    "print(\"\\nReporte de clasificación:\\n\", classification_report(y_train, y_train_pred))\n",
    "\n",
    "# Evaluar en prueba\n",
    "y_test_pred = model.predict(X_test)\n",
    "print(\"Evaluación en prueba:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(\"\\nReporte de clasificación:\\n\", classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4634661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluación en entrenamiento:\n",
      "Accuracy: 0.7699333333333334\n",
      "ROC AUC Score: 0.7909046590568034\n",
      "\n",
      "Reporte de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.78      0.86    111930\n",
      "           1       0.17      0.65      0.28      8070\n",
      "\n",
      "    accuracy                           0.77    120000\n",
      "   macro avg       0.57      0.72      0.57    120000\n",
      "weighted avg       0.92      0.77      0.82    120000\n",
      "\n",
      "\n",
      "Evaluación en prueba:\n",
      "Accuracy: 0.7747\n",
      "ROC AUC Score: 0.7904702375379151\n",
      "\n",
      "Reporte de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.78      0.87     28044\n",
      "           1       0.17      0.66      0.28      1956\n",
      "\n",
      "    accuracy                           0.77     30000\n",
      "   macro avg       0.57      0.72      0.57     30000\n",
      "weighted avg       0.92      0.77      0.83     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
    "\n",
    "# Cargar y preparar datos\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/dt-sc-Josue-Diaz/preentrega/refs/heads/main/data_credit_training.csv')\n",
    "\n",
    "# Preprocesamiento\n",
    "df['MonthlyIncome'] = df['MonthlyIncome'].fillna(df['MonthlyIncome'].median())\n",
    "df['NumberOfDependents'] = df['NumberOfDependents'].fillna(0)\n",
    "df['DebtRatio'] = df['DebtRatio'].clip(upper=1)\n",
    "\n",
    "X = df.drop(columns=['SeriousDlqin2yrs'])\n",
    "y = df['SeriousDlqin2yrs']\n",
    "\n",
    "# Dividir datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Escalar características\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Crear y entrenar el modelo\n",
    "model = LogisticRegression(max_iter=2000, class_weight='balanced')\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluación en entrenamiento\n",
    "y_train_pred = model.predict(X_train_scaled)\n",
    "y_train_proba = model.predict_proba(X_train_scaled)[:, 1]\n",
    "print(\"Evaluación en entrenamiento:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_train, y_train_pred))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_train, y_train_proba))\n",
    "print(\"\\nReporte de clasificación:\\n\", classification_report(y_train, y_train_pred))\n",
    "\n",
    "# Evaluación en prueba\n",
    "y_test_pred = model.predict(X_test_scaled)\n",
    "y_test_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "print(\"\\nEvaluación en prueba:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_test_proba))\n",
    "print(\"\\nReporte de clasificación:\\n\", classification_report(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabad386",
   "metadata": {},
   "source": [
    "# Ayuda de chat\n",
    "Por medio de lo hecho en xgboost hicimos que chatgpt propusiera un algoritmo similar y ver que tanto mejoraba. Para ello tenemos que importar los datos sin tratar como planteamos en el EDA, pues no estaba dando resultado adecuados. Tenemos en esta la importacion que hicimos en la preentrega. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7109904",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/dt-sc-Josue-Diaz/preentrega/refs/heads/main/data_credit_training.csv')\n",
    "df.columns\n",
    "\n",
    "df['MonthlyIncome'] = df['MonthlyIncome'].fillna(df['MonthlyIncome'].median())\n",
    "df['NumberOfDependents'] = df['NumberOfDependents'].fillna(0)  # Si 0 tiene sentido\n",
    "df['DebtRatio'] = df['DebtRatio'].clip(upper=1)\n",
    "\n",
    "X = df.drop(columns=['SeriousDlqin2yrs'])\n",
    "y = df['SeriousDlqin2yrs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb0dafde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "Mejores parámetros: {'C': 0.1, 'class_weight': None, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Modelo guardado como logreg_best_model.joblib\n",
      "ROC-AUC (Entrenamiento): 0.73\n",
      "ROC-AUC (Prueba): 0.72\n",
      "Métricas de clasificación - Entrenamiento\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.67      0.66     97982\n",
      "           1       0.66      0.66      0.66     97982\n",
      "\n",
      "    accuracy                           0.66    195964\n",
      "   macro avg       0.66      0.66      0.66    195964\n",
      "weighted avg       0.66      0.66      0.66    195964\n",
      "\n",
      "---------------------------------------------------------\n",
      "Métricas de clasificación - Prueba\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.67      0.79     41992\n",
      "           1       0.12      0.65      0.21      3008\n",
      "\n",
      "    accuracy                           0.67     45000\n",
      "   macro avg       0.54      0.66      0.50     45000\n",
      "weighted avg       0.91      0.67      0.75     45000\n",
      "\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from joblib import dump\n",
    "import numpy as np\n",
    "\n",
    "# Dividir los datos en entrenamiento y prueba\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.30, random_state=42)\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "# Aplicar SMOTE para balancear clases\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Escalar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Parámetros para GridSearchCV\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'solver': ['liblinear'],\n",
    "    'max_iter': [100, 200],\n",
    "    'penalty': ['l2'],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "# GridSearchCV con LogisticRegression\n",
    "logreg_model = LogisticRegression(random_state=42)\n",
    "grid_search = GridSearchCV(estimator=logreg_model, param_grid=param_grid, cv=3, scoring='roc_auc', n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train_scaled, y_train_resampled)\n",
    "\n",
    "# Mejor modelo\n",
    "best_model = grid_search.best_estimator_\n",
    "print(f\"Mejores parámetros: {grid_search.best_params_}\")\n",
    "\n",
    "# Guardar modelo\n",
    "model_filename = 'logreg_best_model.joblib'\n",
    "dump(best_model, model_filename)\n",
    "print(f\"Modelo guardado como {model_filename}\")\n",
    "\n",
    "# Predicciones y evaluación\n",
    "y_pred_train = best_model.predict(X_train_scaled)\n",
    "y_pred_test = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Obtener las probabilidades para ROC-AUC\n",
    "y_pred_train_proba = best_model.predict_proba(X_train_scaled)[:, 1]\n",
    "y_pred_test_proba = best_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Evaluar en conjunto de entrenamiento y prueba\n",
    "roc_auc_train = roc_auc_score(y_train_resampled, y_pred_train_proba)\n",
    "roc_auc_test = roc_auc_score(y_test, y_pred_test_proba)\n",
    "\n",
    "print(f\"ROC-AUC (Entrenamiento): {roc_auc_train:.2f}\")\n",
    "print(f\"ROC-AUC (Prueba): {roc_auc_test:.2f}\")\n",
    "\n",
    "print(\"Métricas de clasificación - Entrenamiento\")\n",
    "print(classification_report(y_train_resampled, y_pred_train))\n",
    "print(\"---------------------------------------------------------\")\n",
    "\n",
    "print(\"Métricas de clasificación - Prueba\")\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "print(\"---------------------------------------------------------\")\n",
    "\n",
    "# Retornar el modelo y métricas\n",
    "modelo, metricas  = best_model, {\n",
    "    'roc_auc_train': roc_auc_train,\n",
    "    'roc_auc_test': roc_auc_test,\n",
    "    'classification_report_train': classification_report(y_train_resampled, y_pred_train, output_dict=True),\n",
    "    'classification_report_test': classification_report(y_test, y_pred_test, output_dict=True)\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
